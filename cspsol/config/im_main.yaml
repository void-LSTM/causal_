# IM Scenario Configuration: Image as Mediator (T -> I^M -> Y)
# Core principle: Image I^M represents the mediator M in causal chain

# Experiment metadata
name: "im_scenario_main"
description: "Image as Mediator - T affects Y through visual mediator I^M"
tags: ["IM", "image_mediator", "causal_chain"]

# Data configuration
data:
  scenario: "IM"
  data_dir: "./data/CSP-MNIST"
  batch_size: 64
  num_workers: 8
  pin_memory: true
  shuffle_train: true
  val_split: 0.2
  test_split: 0.1
  random_seed: 42
  
  # Data preprocessing
  normalize: true
  standardize: false
  
  # Advanced options
  cache_data: false
  preload_data: false
  
  # Augmentation (minimal for causal preservation)
  augmentation:
    enabled: false
    noise_std: 0.01
    rotation_degrees: 0

# Model architecture configuration
model:
  scenario: "IM"
  z_dim: 128
  
  # Feature dimensions (auto-detected if not provided)
  feature_dims:
    T_dim: 1
    M_dim: 1
    Y_dim: 1
    img_channels: 1
    img_height: 28
    img_width: 28
  
  # Encoder configurations
  encoder_config:
    hidden_dims: [256, 128]
    activation: "relu"
    dropout: 0.1
    batch_norm: true
    
    # Image encoder specific
    img_architecture: "small_cnn"
    img_dropout: 0.1
  
  # Loss function configuration
  loss_config:
    ci:
      enabled: true
      weight: 1.0
      y_type: "cont"
      detach_zm: true
    mbr:
      enabled: true  
      weight: 1.0
      tau: 1.0
      y_type: "cont"
    mac:
      enabled: true
      weight: 0.5
      max_pairs: 4096
    align:
      enabled: true
      weight: 0.3
      temperature: 0.07
    style:
      enabled: false
      weight: 0.1
      style_type: "regression"
      num_styles: 1
    ib:
      enabled: false
      weight: 1e-4
      beta: 1e-4
  
  # Multi-task loss balancing
  balancer_config:
    method: "gradnorm"  # gradnorm, dwa, fixed
    alpha: 0.5
    update_freq: 50
    lr: 0.025
    initial_weights:
      ci: 1.0
      mbr: 1.0
      mac: 0.5
      align: 0.3
      style: 0.1
      ib: 0.01
  
  # Training phase configuration
  phase_config:
    warmup1_epochs: 15
    warmup2_epochs: 25
    warmup1_losses: ["align", "mac"]
    warmup2_losses: ["ci", "mbr", "mac", "align"]
    full_losses: ["ci", "mbr", "mac", "align"]

# Training configuration
training:
  max_epochs: 100
  learning_rate: 1e-3
  weight_decay: 1e-4
  
  # Optimizer
  optimizer: "adamw"
  optimizer_config:
    betas: [0.9, 0.999]
    eps: 1e-8
  
  # Learning rate scheduler
  scheduler: "cosine_warmup_restarts"
  scheduler_config:
    warmup_epochs: 10
    first_cycle_steps: 50
    cycle_mult: 1.0
    min_lr: 1e-6
    eta_min: 1e-6
  
  # Training dynamics
  gradient_clip_val: 5.0
  gradient_clip_algorithm: "norm"
  accumulate_grad_batches: 1
  
  # Mixed precision
  use_amp: true
  
  # Validation and checkpointing
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  save_every_n_epochs: 10
  
  # Early stopping
  early_stopping_patience: 20
  early_stopping_metric: "val_total_loss"
  early_stopping_mode: "min"
  
  # Logging
  log_every_n_steps: 50

# Evaluation configuration
evaluation:
  # Metrics to compute
  compute_cip: true
  compute_csi: true
  compute_mbri: true
  compute_mac: true
  
  # Evaluation parameters
  significance_level: 0.05
  n_bootstrap: 1000
  
  # Output options
  save_representations: true
  save_metrics: true
  save_plots: true
  
  # Representation extraction
  representation_types: ["z_T", "z_M", "z_Y"]
  
  # Analysis options
  detailed_analysis: true
  compare_baselines: false

# Experiment setup
output_dir: "./experiments/im_main"
random_seed: 42
device: "auto"  # auto, cpu, cuda, cuda:0, etc.

# Reproducibility
deterministic: true
benchmark: false

# Testing configuration (for validation)
_test_config:
  expected_scenario: "IM"
  expected_z_dim: 128
  expected_losses: ["ci", "mbr", "mac", "align"]
  expected_phases: 3